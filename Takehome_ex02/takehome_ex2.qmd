---
title: "Take Home Exercise 2"
date: "4 Decemeber 2023"
date-modified: "last-modified"
format: html
execute:
  echo: true
  eval: true
  warning: false
editor: visual
---

## Getting Started

```{r}
pacman::p_load(tmap,sf,spdep,sfdep,tidyverse,knitr,plotly)
```

## Preparing the Flow Data

### Importing the Water Point data

Firstly, we will import the **Water Point Data Exchange PLUS** data set downloaded from Water Point Data Exchange by using read_csv() of **readr** package.

```{r}
wpdx <- read_csv("data/aspatial/WPdx_Plus.csv")
```

### Extracting the Study Data

Check wpdx tibble data frame

```{r}
glimpse(wpdx)
```

Note: We see from above that some of the column names are prefixed with '\#', which may cause issues during wrangling and analysis

Remove '\#' prefix from column names

```{r}

wpdx <- wpdx %>%
  rename_all(~gsub("#", "", .))

```

Select relevant country (i.e. Nigeria) and columns

```{r}

wp <- wpdx %>%
  filter(clean_country_name == "Nigeria") %>%
  select(
    lat_deg,
    lon_deg,
    status_id,
    water_source_category,
    water_tech_category,
    facility_type,
    clean_adm1,
    clean_adm2,
    status_clean,
    distance_to_primary_road,
    distance_to_secondary_road,
    distance_to_tertiary_road,
    distance_to_city,
    distance_to_town,
    water_point_population,
    usage_capacity
  )

#convert to sf
wp_sf <- st_as_sf(wp, coords = c("lon_deg", "lat_deg"), crs = 26391)
```

Check resulting data tables

```{r}
kable(head(wp)) 
```

Output saved in rds format for future use

```{r}
write_rds(wp, "data/rds/wp.rds") 
```

Import the rds file into R environment

```{r}
wp <- read_rds("data/rds/wp.rds") 
```

## Working with Geospatial Data

The following geospatial data (shapefile) will be used for this exercise:

-   Nigeria Level-2 Administrative Boundary (aka Local Government Area) polygon features GIS data

### Importing geospatial data

```{r}
map <- st_read(dsn = "Data/geospatial",
                   layer = "nga_polbndl_adm2_1m_salb") %>%
  st_transform(crs = 26391)
```

Check structure of `map`  sf tibble data frame

```{r}
glimpse(map)
```

Note: The geometry type is linestring, we need to change it to polygon

### Converting linestring to polygons

```{r}
# Buffer the lines to create polygons
buffer_distance <- 0.01  # Adjust this distance based on your data and needs
map_poly <- st_buffer(map, dist = buffer_distance)

# Simplify the resulting polygons to reduce complexity
map_poly <- st_simplify(map_poly)
```

## Geospatial Data Wrangling

Ensure that wp_sf and map_poly have the same CRS

```{r}
st_crs(wp_sf)
st_crs(map_poly)
```

Note: Both datasets confirmed to be EPSG 26391

## Proportion of Functional and Non-Functional Water Points

Tidyr and dplyr methods are used to derive the proportion of functional and non-functional water point at LGA level (i.e. ADM2).

```{r}
wp_sf_status <- wp_sf %>%
  select(status_clean)
```

Group data by *status_clean* column and count occurence of each category

```{r}
wp_sf_status_grp <- wp_sf %>%
  count(status_clean)

wp_sf_status_grp
```

Note: Based on the output above, there are 6 categories. We will combine them into 2 categories.

Non-functional: "Abandoned/Decommissioned", "Non-functional", "Non-Functional, dry season"

Functional: "Functional", "Functional, needs repair", "Functional, not in use"

```{r}

wp_sf_status_grp <- wp_sf %>%
  mutate(filtered_status = case_when(
    status_clean %in% c("Abandoned/Decommissioned", "Non-Functional", "Non-Functional, dry season") ~ "N",
    status_clean %in% c("Functional", "Functional, needs repair", "Functional, not in use") ~ "F",
    TRUE ~ as.character(status_clean)  # Keep other categories as is
  ))
```

Group data by *filtered_status* column and count occurrence of each category

```{r}
count <- wp_sf_status_grp %>%
  count(filtered_status)

count
```

Proportion of Functional vs Non-Functional Water Points

```{r}

proportion_summary <- wp_sf_status_grp %>%
  group_by(filtered_status) %>%
  summarize(proportion = n() / nrow(wp_sf))

# Print the summary
print(proportion_summary)
```

::: {.callout-tip title="Statistical Conclusion" style="color: blue"}
Based on the output above, there are:

|                                      |              |                |
|--------------------------------------|--------------|----------------|
| **Functional Status of Water Point** | **Quantity** | **Proportion** |
| Functional                           | 53015        | 0.5341885      |
| Non-Functional                       | 46229        | 0.4658115      |
:::

## Combining wp_sf_status_grp and map_poly

```{r}
wp_map <- st_intersection(wp_sf_status_grp, map_poly) %>%
  select(BUS_STOP_N, SUBZONE_C)
```

## **Choropleth Visualisation**

#### **Weekday Morning Peak 6am-9am**

Sum up the trips per hexagon

```{r}
total_trips_by_grid_wdmp <- wdmp_gridid %>%
  group_by(grid_id) %>%
  summarise(total_trips = sum(TRIPS, na.rm = TRUE))

```

Merge geospatial data

```{r}

total_trips_by_grid_wdmp <- total_trips_by_grid_wdmp %>%
  left_join(honeycomb_grid_sf, by = c("grid_id" = "grid_id"))

total_trips_by_grid_wdmp_sf <- st_sf(total_trips_by_grid_wdmp)
```

Summary Statistics (Hexagon)

```{r}
summary(wdmp$TRIPS)
```

Total Trips in the time slot

```{r}
sum(wdmp$TRIPS)
```

Plot the Choropleth map

```{r}

tmap_mode("plot")

tm_shape(total_trips_by_grid_wdmp_sf) +
  tm_fill(
    col = "total_trips",
    palette = "Greens",
    style = "cont",
    title = "Total Trips Taken - Weekday Morning Peak 6-9am",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c(
      "Number of trips: " = "total_trips"
    ),
    popup.format = list(
      total_trips = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.4)
```

::: {.callout-tip title="Description of Spatial Patterns" style="color: green"}
Weekday Morning Peak 6am-9am

This timeslot has a total of 26,430,413 trips taken. It ranks first by total volume of trips among our time periods of interest. The median number of trips per hexagon is 2184.

Hexagons with greater number of trips are located near:

-   Residential areas e.g. Tampines, Ang Mo Kio

-   Public transport hubs e.g. Bus Interchange, MRT Interchange e.g. Toa Payoh Interchange, Bedok Interchange

-   Immigration checkpoint at Woodlands
:::

## **Global Spatial Autocorrelation**

Computed to perform spatial complete randomness test for global spatial autocorrelation.

### **Computing Contiguity Spatial Weights**

Use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries.

#### **Weekday Morning Peak 6am-9am**

```{r}
wm_wdmp <- poly2nb(total_trips_by_grid_wdmp_sf, 
                queen=TRUE)
summary(wm_wdmp)
```

Note: The summary report above shows that there are 1490 hexagons considered for Weekday Morning Peak 6am-9am. The most connected hexagon has 6 neighbours. There are 43 hexagons with only 1 neighbour.

### **Row-standardised weights matrix**

Assign weights to each neighboring polygon

```{r}
rswm_wdmp <- nb2listw(wm_wdmp, 
                   style="W", 
                   zero.policy = TRUE)
rswm_wdmp
```

### **Global Spatial Autocorrelation: Moran's I test**

#### **Weekday Morning Peak 6am-9am**

```{r}
moran.test(total_trips_by_grid_wdmp_sf$total_trips, 
           listw=rswm_wdmp, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

::: {.callout-tip title="Statistical Conclusion" style="color: blue"}
**Weekday Morning Peak 6am-9am**

The Moran's I statistic is significantly different from what would be expected under spatial randomness. The positive Moran's I value and the small p-value (\<0.05) suggest a statistically significant spatial clustering pattern. Therefore, there is evidence of spatial autocorrelation in the variable being analysed. The alternative hypothesis that there is a spatial clustering pattern is supported.
:::

### Computing Monte Carlo Moran's I Statistic

Seed 1234 is used for consistency and a total of 1000 simulations will be performed

#### **Weekday Morning Peak 6am-9am**

```{r}
set.seed(1234)

bperm_wdmp = moran.mc(total_trips_by_grid_wdmp_sf$total_trips,
                      listw = rswm_wdmp,
                      nsim = 999,
                      zero.policy = TRUE,
                      na.action = na.omit)
bperm_wdmp
```

### Visualising Carlo Moran's I

#### **Weekday Morning Peak 6am-9am**

```{r}
hist(bperm_wdmp$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```

## **Cluster and Outlier Analysis**

Evaluare existence of clusters in the spatial arrangement of trips in time periods of interest e.g. Weekday Morning Peak 6am-9am.

### Computing Local Moran's I

#### **Weekday Morning Peak 6am-9am**

```{r}
localMI_wdmp <- localmoran(total_trips_by_grid_wdmp_sf$total_trips, rswm_wdmp)
head(localMI_wdmp)
```

Note: localmoran() function returns a matrix of values whose columns are:

-   Ii: the local Moran's I statistics

-   E.Ii: the expectation of local Moran statistic under the randomisation hypothesis

-   Var.Ii: the variance of local Moran statistic under the randomisation hypothesis

-   Z.Ii:the standard deviate of local Moran statistic

-   Pr(): the p-value of local Moran statistic

## Mapping Local Moran's I values & P-values

Append the local Moran's I dataframe (i.e. localMI) onto total_trips_by_grid spatialPolygonDataFrame.

```{r}
ttbg_sf.localMI_wdmp <- cbind(total_trips_by_grid_wdmp_sf,localMI_wdmp) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

## Creating a LISA Cluster Map

Shows the significant locations colour coded by type of spatial autocorrelation.

### **Preparing LISA Map Classes**

Create an empty numeric vector named quadrant with a length equal to the number of rows in the object localMI

```{r}
quadrant_wdmp <- vector(mode="numeric",length=nrow(localMI_wdmp))
```

Setting Significance Level

```{r}
signif <- 0.05
```

#### **Weekday Morning Peak 6am-9am**

```{r}

# Derives the spatially lagged variable of interest (i.e. Total Trips) and centers the spatially lagged variable around its mean

total_trips_by_grid_wdmp_sf$total_trips_lag <- lag.listw(rswm_wdmp, total_trips_by_grid_wdmp_sf$total_trips)
DV_wdmp <- total_trips_by_grid_wdmp_sf$total_trips_lag - mean(total_trips_by_grid_wdmp_sf$total_trips_lag)

#centering the local Moran’s around the mean

LM_I_wdmp <- localMI_wdmp[,1]

#The four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.

quadrant_wdmp[DV_wdmp <0 & LM_I_wdmp>0] <- 1
quadrant_wdmp[DV_wdmp >0 & LM_I_wdmp<0] <- 2
quadrant_wdmp[DV_wdmp <0 & LM_I_wdmp<0] <- 3  
quadrant_wdmp[DV_wdmp >0 & LM_I_wdmp>0] <- 4    

#non-significant Moran placed in the category 0

quadrant_wdmp[localMI_wdmp[,5]>signif] <- 0
```

### **Plotting LISA map**

Plot both the local Moran's I values map and its corresponding p-values map next to each other for effective interpretation

#### **Weekend/Holiday Morning Peak 11am-2pm**

```{r}

tmap_mode("plot")

total_trips_hmp <- qtm(ttbg_sf.localMI_hmp, "total_trips")

ttbg_sf.localMI_hmp$quadrant <- quadrant_hmp

colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_hmp <- tm_shape(ttbg_sf.localMI_hmp) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant_hmp)))+1], 
          labels = clusters[c(sort(unique(quadrant_hmp)))+1],
          alpha = 0.6) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(total_trips_hmp, LISAmap_hmp, 
             asp=1, ncol=2)
```

::: {.callout-tip title="Statistical Conclusion" style="color: gray"}
Weekend/Holiday Morning Peak 11am-2pm
:::
