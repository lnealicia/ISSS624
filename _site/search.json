[
  {
    "objectID": "Takehome_ex01/takehome_ex1.html",
    "href": "Takehome_ex01/takehome_ex1.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "pacman::p_load(tmap,sf,tidyverse,knitr)"
  },
  {
    "objectID": "Takehome_ex01/takehome_ex1.html#getting-started",
    "href": "Takehome_ex01/takehome_ex1.html#getting-started",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "pacman::p_load(tmap,sf,tidyverse,knitr)"
  },
  {
    "objectID": "Takehome_ex01/takehome_ex1.html#preparing-the-flow-data",
    "href": "Takehome_ex01/takehome_ex1.html#preparing-the-flow-data",
    "title": "Take Home Exercise 1",
    "section": "Preparing the Flow Data",
    "text": "Preparing the Flow Data\n\nImporting the OD data\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\nCheck odbus tibble data frame that values in OROGIN_PT_CODE and DESTINATION_PT_CODE are in numeric data type.\n\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nOrigin & Destination Bus Stop Code\n\nodbus$ORIGIN_PT_CODE &lt;-\nas.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;-\nas.factor(odbus$DESTINATION_PT_CODE)\n\n\n\nExtracting the Study Data\nFilter out data that belong to trips that occur on:\n\n“Weekday” and “6-9am” (wdmp)\n\nwdmp &lt;-  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n“Weekday” and “5-8pm” (wdap)\n\nwdap &lt;-  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n“Weekends/Holiday” and “11am-2pm” (hmp)\n\nhmp &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n“Weekends/Holiday” and “4pm-7pm” (hep)\n\nhep &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nCheck resulting data tables\n\nkable(head(wdmp)) \n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n1973\n\n\n01013\n952\n\n\n01019\n1789\n\n\n01029\n2561\n\n\n01039\n2938\n\n\n01059\n1651\n\n\n\n\nkable(head(wdap)) \n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n8448\n\n\n01013\n7328\n\n\n01019\n3608\n\n\n01029\n9317\n\n\n01039\n12937\n\n\n01059\n2133\n\n\n\n\nkable(head(hmp)) \n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n2273\n\n\n01013\n1697\n\n\n01019\n1511\n\n\n01029\n3272\n\n\n01039\n5424\n\n\n01059\n1062\n\n\n\n\nkable(head(hep))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n3208\n\n\n01013\n2796\n\n\n01019\n1623\n\n\n01029\n4244\n\n\n01039\n7403\n\n\n01059\n1190\n\n\n\n\n\nOutput saved in rds format for future use\n\nwrite_rds(wdmp, \"data/rds/wdmp.rds\") \nwrite_rds(wdap, \"data/rds/wdap.rds\") \nwrite_rds(hmp, \"data/rds/hmp.rds\") \nwrite_rds(hep, \"data/rds/hep.rds\")\n\nImport the rds file into R environment\n\nwdmp &lt;- read_rds(\"data/rds/wdmp.rds\") \nwdap &lt;- read_rds(\"data/rds/wdap.rds\") \nhmp &lt;- read_rds(\"data/rds/hmp.rds\") \nhep &lt;- read_rds(\"data/rds/hmp.rds\")"
  },
  {
    "objectID": "Takehome_ex01/takehome_ex1.html#working-with-geospatial-data",
    "href": "Takehome_ex01/takehome_ex1.html#working-with-geospatial-data",
    "title": "Take Home Exercise 1",
    "section": "Working with Geospatial Data",
    "text": "Working with Geospatial Data\nTwo geospatial data (shapefile) will be used for this exercise:\n\nBusStop: Provides location of bus stop as at Q4 2022\nMPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019\n\n\nImporting geospatial data\n\nbusstop &lt;- st_read(dsn = \"Data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\lnealicia\\ISSS624\\Takehome_ex01\\Data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\lnealicia\\ISSS624\\Takehome_ex01\\Data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nCheck structure of busstop and MPSZ  sf tibble data frame\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\nglimpse(mpsz)\n\nRows: 332\nColumns: 7\n$ SUBZONE_N  &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", \"JURON…\n$ SUBZONE_C  &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MPSZ05\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WESTERN …\n$ PLN_AREA_C &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\", \"SI\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"WEST…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\", \"CR\",…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((33222.98 29..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Takehome_ex01/takehome_ex1.html#geospatial-data-wrangling",
    "href": "Takehome_ex01/takehome_ex1.html#geospatial-data-wrangling",
    "title": "Take Home Exercise 1",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nCombining Busstop & mpsz\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nSave output into rds format\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.csv\")"
  },
  {
    "objectID": "Takehome_ex01/takehome_ex1.html#setting-up-the-hexagon-grid",
    "href": "Takehome_ex01/takehome_ex1.html#setting-up-the-hexagon-grid",
    "title": "Take Home Exercise 1",
    "section": "Setting up the Hexagon Grid",
    "text": "Setting up the Hexagon Grid\n\nDrawing the Hexagon Grid\nDraw hexagon grid over the mpsz map\n\narea_honeycomb_grid = st_make_grid(mpsz, c(500, 500), what = \"polygons\", square = FALSE)\n\nConvert the hexagon grid to sf (simple features) object and add a new column grid_id (sequential identifier) to it\n\nhoneycomb_grid_sf = st_sf(area_honeycomb_grid) %&gt;%\n  # add grid ID\n  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))\n\nDetermine which bus stops is contained within which hexagon using st_within.\n\nbusstop_honeycomb &lt;- st_intersection(honeycomb_grid_sf,busstop) %&gt;%\n  select(BUS_STOP_N, grid_id) %&gt;%\n  st_drop_geometry()\n\nSave output into rds format\n\nwrite_rds(busstop_honeycomb, \"data/rds/busstop_honeycomb.csv\")\n\nCheck for duplicate records\n\nduplicate &lt;- busstop_honeycomb %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nRetain unique records only\n\nbusstop_honeycomb &lt;- unique(busstop_honeycomb)\n\nOnly include hexagon grid IDs that have bus stop numbers\n\nbusstop_honeycomb &lt;- busstop_honeycomb %&gt;%\n  filter(!is.na(grid_id) & grid_id &gt; 0)\n\n\n\nAssign Each Bus Stop to a Grid ID\nFor all time periods, assign bus stops to a hexagon grid id. All NULL and 0 values are removed.\n\nwdmp_gridid &lt;- left_join(busstop_honeycomb, wdmp,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\nwdmp_gridid &lt;- wdmp_gridid %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\nwdap_gridid &lt;- left_join(busstop_honeycomb, wdap,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\nwdap_gridid &lt;- wdap_gridid %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\nhmp_gridid &lt;- left_join(busstop_honeycomb, hmp,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\nhmp_gridid &lt;- hmp_gridid %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\nhep_gridid &lt;- left_join(busstop_honeycomb, hep,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\nhep_gridid &lt;- hep_gridid %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)"
  },
  {
    "objectID": "Takehome_ex01/takehome_ex1.html#choropleth-visualisation",
    "href": "Takehome_ex01/takehome_ex1.html#choropleth-visualisation",
    "title": "Take Home Exercise 1",
    "section": "Choropleth Visualisation",
    "text": "Choropleth Visualisation\n\nWeekday Morning Peak 6am-9am\nSum up the trips per hexagon\n\ntotal_trips_by_grid &lt;- wdmp_gridid %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"plot\")\n\ntm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Morning Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\n\n\n\n\n\n\n\n\n\nDescription of Spatial Patterns\n\n\n\n200 words\n\n\n\n\nWeekday Afternoon Peak 5pm-8pm\nSum up the trips per hexagon\n\ntotal_trips_by_grid &lt;- wdap_gridid %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"plot\")\n\ntm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Afternoon Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\n\n\n\n\n\n\n\n\n\nDescription of Spatial Patterns\n\n\n\n200 words\n\n\n\n\nWeekend/Holiday Morning Peak 11am-2pm\nSum up the trips per hexagon\n\ntotal_trips_by_grid &lt;- hmp_gridid %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"plot\")\n\ntm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Greens\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekend/Holiday Morning Peak 11am-2pm\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\n\n\n\n\n\n\n\n\n\nDescription of Spatial Patterns\n\n\n\n200 words\n\n\n\n\nWeekend/Holiday Evening Peak 4pm-7pm\nSum up the trips per hexagon\n\ntotal_trips_by_grid &lt;- hep_gridid %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"plot\")\n\ntm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Greens\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekend/Holiday Evening Peak 4pm-7pm\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\n\n\n\n\n\n\n\n\n\nDescription of Spatial Patterns\n\n\n\n200 words"
  },
  {
    "objectID": "Takehome_ex01/takehome_ex1.html#local-indicators-of-spatial-association-lisa-analysis",
    "href": "Takehome_ex01/takehome_ex1.html#local-indicators-of-spatial-association-lisa-analysis",
    "title": "Take Home Exercise 1",
    "section": "Local Indicators of Spatial Association (LISA) Analysis",
    "text": "Local Indicators of Spatial Association (LISA) Analysis\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is written by Loh Nian En Alicia as part of the ISSS624 Applied Geospatial Data Analysis from the Singapore Management University - Masters of IT in Business (Analytics Track)."
  }
]